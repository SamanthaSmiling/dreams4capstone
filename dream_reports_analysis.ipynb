{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dream Memory NLP Analysis\n",
        "\n",
        "The NLP analysis on dream memories from the sythentic dataset will focus on:\n",
        "1. Sentiment Analysis - Positivity/negativity of dream content\n",
        "2. Emotional Tone - Emotion intensity and valence\n",
        "3. Coherence Analysis - Logical flow between sentences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  - argentina_dream_study_month1.csv\n",
            "  - argentina_dream_study_month2.csv\n",
            "  - argentina_dream_study_month3.csv\n",
            "  - argentina_dream_study_month4.csv\n",
            "  - argentina_dream_study_month5.csv\n",
            "  - usa_dream_study_month2.csv\n",
            "  - usa_dream_study_month3.csv\n",
            "  - usa_dream_study_month1.csv\n",
            "  - usa_dream_study_month4.csv\n",
            "  - usa_dream_study_month5.csv\n",
            "Total merged dataset: 2050 rows\n",
            "Columns: ['ParticipantID', 'Timepoint', 'Country', 'StartDate', 'EndDate', 'Status', 'IPAddress', 'Progress', 'Duration (in seconds)', 'Finished', 'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName', 'RecipientEmail', 'ExternalReference', 'LocationLatitude', 'LocationLongitude', 'DistributionChannel', 'UserLanguage', 'InformedConsent', 'Demo_Age', 'Demo_Education', 'Demo_Student', 'Demo_Gender', 'GAD_Bothered_1', 'GAD_Bothered_2', 'GAD_Bothered_3', 'GAD_Bothered_4', 'GAD_Bothered_5', 'GAD_Bothered_6', 'GAD_Bothered_7', 'GAD_DifficultWork_1', 'PHQ_Bothered_1', 'PHQ_Bothered_2', 'PHQ_Bothered_3', 'PHQ_Bothered_4', 'PHQ_Bothered_5', 'PHQ_Bothered_6', 'PHQ_Bothered_7', 'PHQ_Bothered_8', 'PHQ_Bothered_9', 'PHQ_DifficultWork_1', 'GAD_Total', 'PHQ_Total', 'Sleep_Alarm', 'Sleep_AlarmFrequency', 'Sleep_Bedtime', 'Sleep_Timetosleep', 'Sleep_Medication', 'Sleep_Quality', 'Sleep_Hours', 'Sleep_Disturbed', 'Sleep_Morning/Eve', 'DreamMemory', 'Dream_Feelings', 'Dream_Talk', 'Dream_TalkWhom', 'Dream_Write', 'Dream_Content', 'DreamQ_Frequency', 'More_LucidDream', 'DreamQ_Vivid_1', 'DreamQ_Bizarre_1', 'DreamQ_Recurring', 'DreamQ_FeelControl_1', 'DreamQContentControl_1', 'DreamQ_ControlFreq_1', 'More_DreamIntensity_1', 'More_EmotionalTone_1', 'More_DreamDistress_1', 'More_Childhood_1', 'More_BadDreams', 'More_BadDreamReality', 'More_BadDreamRecurr', 'More_Nightmares', 'MorNightmaredistress', 'More_NightmareFreq', 'MoreNightmareReality', 'More_NightmareRecurr', 'More_DreamList', 'More_Coffee', 'More_CoffeeCups', 'More_CoffeeTime', 'More_Stimulants', 'More_AlcoholFreq', 'More_AlcoholAmount', 'More_Cigarettes', 'More_LivingSituation', 'More_Pets', 'ProlificID', 'PROLIFIC_PID']\n"
          ]
        }
      ],
      "source": [
        "# Load all CSVs (in real case, it will be multiple csv files too)\n",
        "data_dir = Path('chaos_dataset')\n",
        "csv_files = list(data_dir.glob('*.csv'))\n",
        "\n",
        "for file in csv_files:\n",
        "    print(f\"  - {file.name}\")\n",
        "\n",
        "# Load and merge\n",
        "all_data = []\n",
        "\n",
        "for file in csv_files:\n",
        "    df = pd.read_csv(file)\n",
        "    all_data.append(df)\n",
        "\n",
        "# Combine all dataframes\n",
        "merged_data = pd.concat(all_data, ignore_index=True)\n",
        "print(f\"Total merged dataset: {len(merged_data)} rows\")\n",
        "print(f\"Columns: {list(merged_data.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records: 2050\n",
            "Records with DreamMemory: 2050\n",
            "Missing DreamMemory: 0\n",
            "Working with 2050 dream records\n",
            "Samples:\n",
            "0    I was being chased by something threatening bu...\n",
            "1    I was being chased by something threatening bu...\n",
            "2    I was searching for something important but co...\n",
            "Name: DreamMemory, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# DreamMemory extraction\n",
        "# na checking\n",
        "print(f\"Total records: {len(merged_data)}\")\n",
        "print(f\"Records with DreamMemory: {merged_data['DreamMemory'].notna().sum()}\")\n",
        "print(f\"Missing DreamMemory: {merged_data['DreamMemory'].isna().sum()}\")\n",
        "\n",
        "# filter records with dream memories\n",
        "dream_data = merged_data[merged_data['DreamMemory'].notna()].copy()\n",
        "print(f\"Working with {len(dream_data)} dream records\")\n",
        "\n",
        "# Show samples\n",
        "print(\"Samples:\")\n",
        "print(dream_data['DreamMemory'].head(3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Sentiment Analysis - Positivity/Negativity\n",
        "\n",
        "We will analyze the emotional polarity of the dream content using multiple sentiment analysis approaches - VADER for basic tone and textBlob for double check. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required packages...\n",
            "Collecting textblob\n",
            "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: nltk>=3.9 in /opt/anaconda3/lib/python3.11/site-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.9->textblob) (8.2.1)\n",
            "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.9->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.9->textblob) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.3/624.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hInstalling collected packages: textblob\n",
            "Successfully installed textblob-0.19.0\n",
            "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.11/site-packages (3.9.1)\n",
            "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from vaderSentiment) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->vaderSentiment) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->vaderSentiment) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->vaderSentiment) (2024.8.30)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# packages for sentiment analysis\n",
        "try:\n",
        "    from textblob import TextBlob\n",
        "    import nltk\n",
        "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "    print(\"Sentiment analysis libraries already available\")\n",
        "except ImportError:\n",
        "    print(\"Installing required packages...\")\n",
        "    import subprocess\n",
        "    import sys\n",
        "    \n",
        "    def install_package(package):\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "    \n",
        "    install_package(\"textblob\")\n",
        "    install_package(\"nltk\")\n",
        "    install_package(\"vaderSentiment\")\n",
        "    \n",
        "    from textblob import TextBlob\n",
        "    import nltk\n",
        "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "    \n",
        "    # Download required NLTK data\n",
        "    nltk.download('vader_lexicon', quiet=True)\n",
        "    \n",
        "    print(\"installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing ...\n",
            "Processed 100/2050 dreams...\n",
            "Processed 200/2050 dreams...\n",
            "Processed 300/2050 dreams...\n",
            "Processed 400/2050 dreams...\n",
            "Processed 500/2050 dreams...\n",
            "Processed 600/2050 dreams...\n",
            "Processed 700/2050 dreams...\n",
            "Processed 800/2050 dreams...\n",
            "Processed 900/2050 dreams...\n",
            "Processed 1000/2050 dreams...\n",
            "Processed 1100/2050 dreams...\n",
            "Processed 1200/2050 dreams...\n",
            "Processed 1300/2050 dreams...\n",
            "Processed 1400/2050 dreams...\n",
            "Processed 1500/2050 dreams...\n",
            "Processed 1600/2050 dreams...\n",
            "Processed 1700/2050 dreams...\n",
            "Processed 1800/2050 dreams...\n",
            "Processed 1900/2050 dreams...\n",
            "Processed 2000/2050 dreams...\n",
            "Sentiment analysis complete! Analyzed 2050 dreams.\n"
          ]
        }
      ],
      "source": [
        "def analyze_sentiment_textblob(text):\n",
        "    blob = TextBlob(str(text))\n",
        "    return {\n",
        "        'polarity': blob.sentiment.polarity,  # -1 (negative) to 1 (positive)\n",
        "        'subjectivity': blob.sentiment.subjectivity  # 0 (objective) to 1 (subjective)\n",
        "    }\n",
        "\n",
        "def analyze_sentiment_vader(text):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    scores = sia.polarity_scores(str(text))\n",
        "    return {\n",
        "        'compound': scores['compound'],  # Overall sentiment\n",
        "        'positive': scores['pos'],\n",
        "        'negative': scores['neg'],\n",
        "        'neutral': scores['neu']\n",
        "    }\n",
        "\n",
        "print(\"Performing ...\")\n",
        "\n",
        "# Apply sentiment analysis\n",
        "sentiment_results = []\n",
        "\n",
        "for idx, dream in enumerate(dream_data['DreamMemory']):\n",
        "    if pd.notna(dream) and str(dream).strip():\n",
        "        # TextBlob analysis\n",
        "        tb_sentiment = analyze_sentiment_textblob(dream)\n",
        "        \n",
        "        # VADER analysis\n",
        "        vader_sentiment = analyze_sentiment_vader(dream)\n",
        "        \n",
        "        sentiment_results.append({\n",
        "            'index': idx,\n",
        "            'dream_text': dream,\n",
        "            'tb_polarity': tb_sentiment['polarity'],\n",
        "            'tb_subjectivity': tb_sentiment['subjectivity'],\n",
        "            'vader_compound': vader_sentiment['compound'],\n",
        "            'vader_positive': vader_sentiment['positive'],\n",
        "            'vader_negative': vader_sentiment['negative'],\n",
        "            'vader_neutral': vader_sentiment['neutral']\n",
        "        })\n",
        "    \n",
        "    if (idx + 1) % 100 == 0:\n",
        "        print(f\"Processed {idx + 1}/{len(dream_data)} dreams...\")\n",
        "\n",
        "sentiment_df = pd.DataFrame(sentiment_results)\n",
        "print(f\"Sentiment analysis complete! Analyzed {len(sentiment_df)} dreams.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment Analysis Summary:\n",
            "Average TextBlob Polarity: 0.033\n",
            "Average VADER Compound: -0.319\n",
            "Average Subjectivity: 0.399\n",
            "Sentiment Categories:\n",
            "  Negative: 1472 (71.8%)\n",
            "  Neutral: 297 (14.5%)\n",
            "  Positive: 281 (13.7%)\n"
          ]
        }
      ],
      "source": [
        "# summary statistics\n",
        "print(\"Sentiment Analysis Summary:\")\n",
        "print(f\"Average TextBlob Polarity: {sentiment_df['tb_polarity'].mean():.3f}\")\n",
        "print(f\"Average VADER Compound: {sentiment_df['vader_compound'].mean():.3f}\")\n",
        "print(f\"Average Subjectivity: {sentiment_df['tb_subjectivity'].mean():.3f}\")\n",
        "print(f\"Sentiment Categories:\")\n",
        "for category, count in category_counts.items():\n",
        "    print(f\"  {category}: {count} ({count/len(sentiment_df)*100:.1f}%)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
